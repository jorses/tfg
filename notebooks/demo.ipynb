{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Libraries and Tools used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Our graphical elements are going to be done with matplotlib, inline graphs\"\"\"\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"CSV: utility to work with the most common format for datastorage : Comma Separated Values\"\"\"\n",
    "import csv\n",
    "\"\"\"JSON: utility to work with JavaScript Object Notation, the original information format storage we \"\"\"\n",
    "import json\n",
    "from collections import namedtuple\n",
    "\"\"\"Pandas: python's most used library to work with datasets\"\"\"\n",
    "import pandas as pd \n",
    "\"\"\"Numpy: python's most used library to work with large amounts of numbers\"\"\"\n",
    "import numpy as np\n",
    "\"\"\"OS: utility to work with paths and file openings independently of operating system\"\"\"\n",
    "import os\n",
    "\"\"\"Glob: used to look for file extensions inside given folders\"\"\"\n",
    "import glob \n",
    "\n",
    "\"\"\"Candidates for ML predictive model implementations\"\"\"\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import catboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Storage module\n",
    "\n",
    "### Methods \n",
    "\n",
    "#### __init__\n",
    "#### print_info\n",
    "#### from_json\n",
    "#### to_json\n",
    "#### update_stats\n",
    "#### load_from_dataframe\n",
    "### TODO\n",
    "- Set paths as environment variables (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StoreDomain:\n",
    "    \n",
    "    def __init__(self, domain_name=None, attribute_list=None, knowledge=None):\n",
    "        \"\"\" Handy initialization, if no values are provided everything is set to None\n",
    "            This way we can check wether an attribute has been set by doing \n",
    "            if not self.{attribute} \n",
    "        \"\"\"\n",
    "        \n",
    "        self.domain_name = domain_name\n",
    "        self.attribute_list = attribute_list\n",
    "        self.knowledge = knowledge\n",
    "\n",
    "    def from_json(self,data):\n",
    "        \"\"\" Loads the class from a physical representation (dict) of it\n",
    "        \"\"\"\n",
    "        \n",
    "        self.domain_name = data[\"domain_name\"]\n",
    "        self.domain_name = data[\"attribute_list\"]\n",
    "        self.knowledge = data[\"knowledge\"]\n",
    "\n",
    "    def print_info(self):\n",
    "        \"\"\" Util to print attributes\n",
    "        \"\"\"\n",
    "        print(self.domain_name, self.attribute_list, self.knowledge)\n",
    "        \n",
    "\n",
    "    def load_from_dataframe(self, df, paths=[os.getcwd()]):\n",
    "        \"\"\" Given a dataset searches for a domain in the specified folder(s)\n",
    "        \"\"\"\n",
    "        found = False\n",
    "        for path in paths:\n",
    "            for fnm in glob.glob(os.path.join(path,\"*.json\")):\n",
    "                with open(fnm) as f:\n",
    "                    data = json.load(f)\n",
    "                if data[\"attribute_list\"] == list(df.columns):\n",
    "                    self.from_json(data)\n",
    "                    found = True\n",
    "                    break;\n",
    "        \n",
    "        if not found:\n",
    "            print(\"No matching knowledge found for your domain, setting an empty one\")\n",
    "            self.attribute_list = list(df.columns)\n",
    "            self.domain_name = df.name\n",
    "            self.knowledge = {}\n",
    "\n",
    "    # Open all files \n",
    "    def update_stats(self, knowledge):\n",
    "        \"\"\" Syntactic sugar used by the analyzer to update the domain knowledge before saving it\n",
    "        \"\"\"\n",
    "        self.knowledge = knowledge\n",
    "        \n",
    "    def to_json(self,fnm=None):\n",
    "        \"\"\" Saves itself as an object in .json format given in the specificed fnm\n",
    "        \"\"\"\n",
    "        if fnm is None:\n",
    "            fnm = df.name + \".json\"\n",
    "        with open(fnm,'w') as f:\n",
    "            json.dump(self.__dict__, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/brick/Desktop/Uni/tfg/notebooks']\n",
      "['a', 'b'] None {'dataset_stats': {'individuals': 0, 'max_rows': {'value': 1400, 'metric': 'count_rows_null'}, 'avg_rows': {'value': 1400, 'metric': 'count_rows_null'}, 'full_rows': {'value': 0.97}}, 'column_stats': {'a': {'type': 'numeric', 'color': 'blue', 'stats': {'median': 12.6, 'std_dev': 1.3, 'max': 25.5, 'min': 2.3, 'NaNs': 0.02}}, 'b': {'type': 'categorical', 'color': 'red', 'stats': {'most_frequent': 'cat', 'values': {'cat': 0.2, 'dog': 0.6}, 'nan': 0.1}}}}\n"
     ]
    }
   ],
   "source": [
    "## StoreDomain tests\n",
    "\n",
    "df = pd.read_csv(\"nonsense.csv\")\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "df.name = \"nonzenze\"\n",
    "std = StoreDomain()\n",
    "\n",
    "std.load_from_dataframe(df)\n",
    "std.knowledge = KNOWLEDGE_STRUCTURE\n",
    "\n",
    "std.to_json()\n",
    "std.print_info()\n",
    "#dom = sd.domain_from_dataset(ds,paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [1, 2], 'b': 2}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.loads(json.dumps({\"a\":[1,2], \"b\":2}))\n",
    "b = {}\n",
    "for k,v in data.items():\n",
    "    b[k] = data[k]\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The JSON\n",
    "&nbsp;\n",
    "\n",
    " This object is used to represent the raw information stored.\n",
    "\n",
    " It contains statistics and properties from both statistics and datasets, different to different types, as well as how they were measured (by saving the function to be called on a pandas dataset in the case of a dataset stat, or on the values themselves in the case of a function stat).\n",
    "\n",
    " Saving how they're measured is important to measure new datasets and to be able to compare metrics effectively.\n",
    "\n",
    " Both the column specific stats and the dataset stats are subjective to change, and the knowledgedomain object can be modified and adapted to fit new parameters easily.\n",
    "\n",
    " This structure is generated for a single dataset and then combined with the domain one to take account of the new one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNOWLEDGE_STRUCTURE = {\n",
    "    \"dataset_stats\": {\n",
    "        \"individuals\": 0,\n",
    "        \"max_rows\": {\n",
    "            \"value\": 1400,\n",
    "            \"metric\" : \"count_rows_null\",\n",
    "        }, # alert if new rows are <<<, as different results are skewed\n",
    "        \"avg_rows\": {\n",
    "            \"value\": 1400,\n",
    "            \"metric\" : \"count_rows_null\"\n",
    "        },\n",
    "        \"full_rows\": {\n",
    "            \"value\": 0.97\n",
    "        }\n",
    "    },\n",
    "    \"column_stats\": {\n",
    "        \"a\": {\n",
    "            \"type\": \"numeric\",\n",
    "            \"color\": \"blue\",\n",
    "            \"stats\": {\n",
    "                \"median\": 12.6,\n",
    "                \"std_dev\": 1.3,\n",
    "                \"max\": 25.5,\n",
    "                \"min\": 2.3,\n",
    "                \"NaNs\": 0.02 # as % of dataset\n",
    "            }\n",
    "            \n",
    "        },\n",
    "        \"b\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"color\": \"red\",\n",
    "            \"stats\": {\n",
    "                \"most_frequent\": \"cat\",\n",
    "                \"values\": {\n",
    "                    \"cat\": 0.2,\n",
    "                    \"dog\": 0.6\n",
    "                },\n",
    "                \"nan\": 0.1\n",
    "            }\n",
    "            \n",
    "        }\n",
    "\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The analysis module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Metrics \"\"\"\n",
    "def count_rows_null(df):\n",
    "    return df.isnull().shape(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DatasetAnalyzer():\n",
    "    def __init__(self, ds, knowledge=None):\n",
    "        self.dataset = ds\n",
    "        if not knowledge:\n",
    "            # now search and load information from domain\n",
    "            self.domain_knowledge = StoreDomain(ds,paths=[])\n",
    "        else:\n",
    "            self.domain_knowledge = knowledge\n",
    "        self.dataset_knowledge = self.get_stats(ds)\n",
    "\n",
    "    def __init__(self,ds,knowledge):\n",
    "        self.dataset = ds\n",
    "        self.domain_knowledge = knowledge\n",
    "        \n",
    "    def load_knowledge(self, dataset):\n",
    "        std = StoreDomain()\n",
    "    def get_stats(self, dataset):\n",
    "        stats = {}\n",
    "        for c in dataset.columns:\n",
    "            #for every column save on the \n",
    "            stats.column_stats[c] = globals()[self.knowledge.column_stats[c].metric](dataset[c].values)\n",
    "        \n",
    "        for k in self.knowledge.dataset_stats:\n",
    "            stats.dataset_stats[k] = globals()[self.knowledge.dataset_stats[k].metric](dataset)\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def compare(self):\n",
    "        # compare self.domain_knowledge and self.dataset_knowledge\n",
    "        # store analysis result in self.result\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReportGenerator:\n",
    "    def __init__(self, analysis_result, domain_info):\n",
    "        self.analysis_result = analysis_result\n",
    "        print(\"  henlo\")\n",
    "        \n",
    "    def generate():\n",
    "        # compare the result analysis with our knowledge of the domain, then select the relevant stuff, store json\n",
    "        \n",
    "        #in self.report_json\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frontend module\n",
    "Logic-free, just turns an information json to a user-readable report with images, which then prints out for the user to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextTemplates:\n",
    "    def __init__(self):\n",
    "    def red_json(self,):\n",
    "PRETTY_JSON = {\n",
    "    \"graphs\": {\n",
    "        \"some_col\":{\n",
    "            \"type\" : \"bars\",\n",
    "            \"cat_colors\" : {\n",
    "                \"cat\" : \"red\",\n",
    "                \"dog\" : \"blue\",\n",
    "            },\n",
    "            \"bg_color\" : \"white\"\n",
    "        }\n",
    "    },\n",
    "    \"text\" : {\n",
    "        \"some_col_avg\" : {\n",
    "            \"reason\" : \"high\",\n",
    "            \"number_ds\" : 1.3,\n",
    "            \"number_domain\": 0.2\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FrontEnd:\n",
    "    def __init__(self, config):\n",
    "        \"\"\"Self explaining, associate graph with \"\"\"\n",
    "        self.graphs_config = config.graphs\n",
    "        self.text_config = config.text\n",
    "    def generate_graphs(self):\n",
    "        for config in self.graphs_config:\n",
    "            print(config)\n",
    "    def generate_text(self):\n",
    "        for config in self.text_config:\n",
    "            print()\n",
    "        #text things\n",
    "        #graphical things\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'knowledge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-04c7d752c31a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"\"\"First we read our data\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nonsense.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#load dataset into analyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#get report generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'knowledge'"
     ]
    }
   ],
   "source": [
    "EXEC_PARAMS = {\n",
    "    \"domain_name\" : \"animals\",\n",
    "    \"attribute_list\": [] ,\n",
    "    \"knowledge\" : KNOWLEDGE_STRUCTURE\n",
    "}\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"First we read our data\"\"\"\n",
    "    df = pd.read_csv(\"nonsense.csv\")\n",
    "    dsa = DatasetAnalyzer(df)\n",
    "    #load dataset into analyzer\n",
    "    #get report generator\n",
    "    #use the froentend module to present it to the user\n",
    "    #if the user gives feedback, frontend saves it as important in the store (?) information\n",
    "    print(\"henlo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
