%---------------------------------------------------------------------
%
%          Capï¿½tulo 2
%
%---------------------------------------------------------------------

\chapter{The Program Implementation : Architecture}


\begin{resumen}
In this chapter we provide a technical analysis of our tool, examining how it works and what was designed for at a programming level, aswell as its module structure, and its relation to the low-level CBR process.
\end{resumen}

\linespread{1.6}

%-------------------------------------------------------------------
\section{The Program Module Structure}
%-------------------------------------------------------------------

First we need to provide our program with a clear programming structure that allows it to be customizable enough, as it is very important that we're able to add new functionality related to new kinds of analysis, users or datasets.

To make it as customizable as possible, we've divided it in modules that have a clear functionality, with the objective that we're able to change an aspect of the program by changing just one module and not the whole program.

All the code is openly hosted at www.github.com/jorses/tfg.

We will have one module which handles the loading and storing of the objective information about domains, one that does the same for user profiles associated to each domain, one that runs an analysis on the dataset and compares it to the domain, and one that puts everything together to generate a report which will be then presented to the user through the frontend module, which handles interactions with the user.

So our hierarchy goes as follows, the frontend module takes input from the user regarding its profile (input done through a dictionary-like object in the proof of concept) and a path to the dataset that is to be analyzed.

This module then relays the information to the two modules that handle information storage. 

The storage module will read the dataset, as a CSV file in the proof of concept, read its columns and search its database for a matching domain information.

In a more advanced version this search would be performed through a lookup on a non relational database like MongoDB, but for the proof of concept it looks in a folder where it stores the domain information objects as JSONs.

When it finds one that matches the column names, it loads the object into a python dictionary and sends it to the analysis module along with the new dataset.

The analysis module then performs an analysis and generates a proto-report with all the objective information about the comparison between the dataset analysis and the domain historical analysis, then passes this along to the report generation module.

In parallel, the module that handles the profile will load it in a way similar to the storage module, then pass it along to the report generation module.

When the report generation module gets all the needed information uses the user-generated profile to "filter" the objective results (as explained later in detail), and extract from them the final info that will then be presented to the user through the frontend module.

The user is able to make changes to this final report (through the console in the proof of concept), and before closing the program

All of this contributes to making the CBR process as streamlined as possible while providing a flexible framework for data handling.

\begin{figure}[!htb]
    \center{\includegraphics[width=\textwidth]
    {Capitulos/information_flow.png}}
    \caption{\label{fig:info_flow}}
\end{figure}

%-------------------------------------------------------------------
\section{Non relational databases and the JSON structure}
%-------------------------------------------------------------------
\label{cap3:sec:jsonfiller}

For the proof of concept implementation developed in this thesis, we've used the JSON structure to handle our information, to write it to a file system and to read it later.

JSON, short for JavaScript Object Notation is a file format that uses text readable by humans to write attribute value pairs and serializable values. 

It is a a very common data format used for general storage of information, and will allow us to do a quick implementation capable of handling enough domains and profiles to test our program, and will allow us to later transfer this information to a non-relational database system such as MongoDB.

Python also allows us to quickly load this kind of object into its native dictionary type, making it easy for our modules to load, manipulate and store the information.

A non relational database is one that does not use the tabular schema of rows and columns found in most typical databases like SQL.

Our need for such a database comes from the fact that not every domain will have the same structure of knowledge for its analysis, with the possibilities of combinations being almost infinite and thus negating any approach to putting it inside a tabular schema.

Inside these databases data may be kept as JSON documents, which is the format that we've chosen.

The proposed database for the final model is MongoDB. 

MongoDB is a non relational database program, which is also cross-platform and document oriented. It works with objects very similar to JSON, and is licensed under the Server Side Public License (SSPL). 

Aside from this, it's easily managed through Python and has native packages to communicate with it, which would make our life easier when implementing the full program.

All of this provides us with a solution catered to our needs, which can be scalated easily if needed into a production ready state, capable of dealing with large amounts of data and providing a real solution to real users.

Every module listed below corresponds to a Python class, and has a number of methods, functions and dictionaries associated to it to perform its function.

%-------------------------------------------------------------------
\section{The Objective Storage Module}
%-------------------------------------------------------------------
\label{cap3:sec:objjson}

This module is capable of reading and updating the information stored about the objective analysis of past domains.

It sits at the lowest point in the hierarchy, as it only does as commanded and is usually handled by the other modules and used as a mere tool to get information, similar to the profile storage module.

Both modules are derived from a more basic Python class, called just Storage, from which they inherit the methods responsible from loading and storing files (or updating and loading from the database, in the scalable version).

This class adds to these functions more advanced tools to deal with the domain information and load it into a dictionary-like object that will then be able to be easily handled by the analysis module, translating information stored in plain text like function names to its equivalent variables and Python dictionaries in the program, using the dictionaries which it has as an attribute.

This process is reversed before writing the information back to disk in a format that can be condensed to JSON documents, mainly turning every function name and other serializable objects back into strings to be stored.

%-------------------------------------------------------------------
\section{The Profile Storage Module}
%-------------------------------------------------------------------
\label{cap3:sec:profilestorage}

Another kind of information is stored. This is the one concerning the human side of things, that is, how to interpret these stats and turn them into something that humans with different levels of familiarity can understand.

To do this, we provide use another storage class that will contain human-relevant data that will modify the objective comparison delivered by the analysis module.

A system of profiles is added to the object itself, inside a "profiles" key. The domain associated is clear as they share the same "attributelist" identification system.

The information contained in each one of these "profiles" serves two different purposes. It provides customizable elements of  how  the data will be presented to the user, and it keeps an historical record of this user's dataset results (similar to the one in the domain storage) making a historical following of a profile possible.

For each domain, there's a default profile. This provides a way to present the data when no previous knowledge of the profile is available. The automated processes of obtaining this profile and tuning the existing profiles from user feedback will be explained in further chapters.

%-------------------------------------------------------------------
\section{The Comparison Metrics}
%-------------------------------------------------------------------
\label{cap3:sec:metrics}

The purpose of these functions is to provide a way to measure the properties of a given dataset or knowledge domain.

We have to note first that not every kind of possible metric has been added to the program, but we've instead added enough to cover the most common types of analysis, mainly detecting distributions, most frequent values, and calculating a series of common metrics over numerical columns.

However, adding a new metric is as simple as providing it with a name, an associated function which fits into the types of one of the metrics listed below, and adding the pair of name,function to a dictionary present in the code.

The rest of the program will behave exactly the same, thus fittinng the design principle mentioned before of being able to expand the program quickly and efficiently.

We can categorize them as follows:

First the "measurement" metrics, used to get the information of a single dataset or domain.
\begin{itemize}
\item Dataset Metrics : they concern the dataset as a whole, like number of rows with missing values.
    dm :: (ds) --> num
    
\item Single Column Metrics : they concern a certain column, and are based on the type of the column.
    For numerical columns we will have things like median, averages, deviations, distributions...
    For categorical columns we'll work with frequencies and things of the sort.
    scm :: (col) --> num
    
\item Multiple Column Metrics : we will be looking for correlations and things of that sort.
    scm :: (col,col) --> num 
    Time based metrics will be defined from this construct.
\end{itemize}

We will also have "comparison" metrics, used to compare datasets against their domains.
These metrics will compare the output of two measurement metrics, both will have to
spawn from the same function.
\begin{itemize}
\item compm :: (metric) --> num
\end{itemize}

Note that these metrics are not to provide "meaning" or any human-readable input, nor to be
inherently comparable between each other outside of a framework of understanding of the domain
(metric importance).

A mean to convert these machine cold metrics into human understanding will be provided in further 
modules. For now, we're not taking humans into account.

%-------------------------------------------------------------------
\section{The Analysis Module}
%-------------------------------------------------------------------
\label{cap3:sec:analysis}

The analysis module will receive a dataset, use the Storage module to load its information, then analyze the dataset, which generates a similar object to the domain json, then producing a comparison of both.

The main methods for this module are  getstats ,  getcolumnstats  and  getdatasetstats .

The  getstats  method is just a wrapper for the other two, calls them both and stores its results inside the Analyzer class.

Both  getcolumnstats  and  getdatasetstats  compute the statistics for the given dataset. If there is previous knowledge of the domain, the stats that appear there are computed for the domain. If not, a standard set of frequencies for categorical values and medians and distributions for numerical values are calculated and used to populate the stats object.

The most important method is  getanalysis . Once the stats for the datasets have been generated, if there's previous knowledge available the class runs an analysis comparing the metrics of the two, and generating an object with the result. For this to happen, each metric defined for the dataset must have an associated  comparison metric .

If there is no previous knowledge then the dataset stats are passed along to the reporter with a field indicating that there was no previous knowledge.

In any case, at this level we've already filtered what is relevant and what is not from the comparison.

%-------------------------------------------------------------------
\section{The Report Generation Module}
%-------------------------------------------------------------------
\label{cap3:sec:reporter}

This module stands at the edge between the backend and the frontend. It receives the information from the comparison between the dataset and the domain knowledge and extracts the relevant profile information.

Once this is done, it uses both to generate a report with all the information from both sides. The user-relevant info will modify what is shown and  how  that is shown, changing the graphical elements according to the user so the frontend modules are able to be logic-free.

It is able to directly modify the profile information by the proxy methods  modify  and  savehumaninfo . Its main method,  generate , will create and populate an attribute within itself called report.

This method is called when the class itself is generated but the report can be modified as any Python attribute if needed.

At this point, we have an object that represents the dataset compared to the historical data and data about the profile associated with the user. This information, however, is in the form of a JSON object and is not really human-readable. The job of the frontend modules is to take this information and turn it into something easy to understand.

%-------------------------------------------------------------------
\section{The Frontend Module}
%-------------------------------------------------------------------
\label{cap3:sec:frontend}

The purpose of this module is to handle the user program interaction. It sits atop of the program hierarchy, being able to use all the other modules as it sees fit.

Its role begins and the very beginning of the program life cycle and ends at the same time the user decides to exit. 

Its functionality is based on the principles of minimalistic design and the user being able to interact with every element of the presented report.

For our proof of concept, a more simple design has been put in place. Instead of clicking on the elements, the user is able to interact with the program through the console.

However, all the functionality is present, as the users can input the information the program requests to generate the profile, and then change the report presented to them using commands too.

When the program is closed the frontend module passes the modified report to the information storage modules, with both the updated objective information and the updated subjective information.

\begin{figure}[!htb]
    \center{\includegraphics[width=\textwidth,height=\textheight/2,keepaspectratio]
    {Capitulos/feedback_loop.png}}
    \caption{\label{fig:feedback_loop}}
\end{figure}

%-------------------------------------------------------------------
\section{Information Storage and the CBR}
%-------------------------------------------------------------------
\label{cap6:sec:informationstorage}

Because the information we're storing is still low and the metrics are different for each domain the only way to consistenly store the information is through a non-relational database.

To provide the information to the experiment and to run this as a proof of concept we can simplify it by storing information in the form of JSON structures, which will be stored as files in a directory accessible by our program.

The relevant information for the use case at hand will be retrieved by our program, stored as a run time variable, modified when needed and then stored back to the JSON overwriting the previous structure.
If we had a non relational database we could simply update the database instead.

\section{Retrieve}
%-------------------------------------------------------------------
\label{cap6:sec:retrieve}
If we're doing a full non-relational database implementation it's probably better to develop a domainID, because that would allow us to have different domains with the same column names.

For the proof of concept though that is not an issue because we've made sure this hasn't happened with the datasets used for the testing.

Retrieving this information is as easy as reading the JSON file and loading into a dictionary type in Python. We know which information to retrieve because each json contains an ID variable with the column list of the datasets from the domain.

We do this with a file buffer the standard way. Once it has been loaded the information is handled by two different classes.

\section{Reuse}
%-------------------------------------------------------------------
\label{cap6:sec:reuse}
The objective information about the domain is loaded and handled by the class that handles the objective information, which will then be passed to the 

The profile or subjective information about the domain and user is handled by the module that handles the profiles, which will then pass it along to the module that generates the report.

This allows us to reuse the previous experiences in the process of generating the report module.

\section{Revise}
%-------------------------------------------------------------------
\label{cap6:sec:revise}
There are two ways on which we can revise the information. If the users from the start say what they want then the system associates what they want as if changes have been made to the report that was going to be presented to them.

In any case, when the users are provided with the report they can provide feedback through a visual interface by selecting which information is shown and shouldn't be shown, what information should be shown but is not the report, and change the colors/fonts of the report.

This allows us a thorough revise step, in which the user has full agency over the results generated by the program and is able to change all the choices that our system has made.

This is incredibly important because it makes our system learn a lot from each interaction.

\section{Retain}
%-------------------------------------------------------------------
\label{cap6:sec:retain}

\begin{figure}[!htb]
    \center{\includegraphics[width=\textwidth]
    {Capitulos/shutdown.png}}
    \caption{\label{fig:shutdown}}
\end{figure}

Once these changes have been made the objective information is updated and written back to disk by the same module that retrieved it through an store method.

The same method is present in the module responsible for handling the profile information, which will update the choices the user has made.

This is a crucial step because it is what allows us to retrieve these changes consistenly if this user or a similar one wants to use the system in the future.

In the end what we've achieved is a system that grows better with each interaction, providing the users with better and easier use experiences every time they use it.

\section{Conclusion}
%-------------------------------------------------------------------
In this chapter we've gone over the detailed implementation of our program, including the specific modules programmed in Python code and their relations to the flexible CBR structure we're trying to achieve.
At this point we have a clear picture of what our program does and how it looks like from a code perspective, and we've specified the different techniques and metrics used to analyze common data types.
However, there is one important question that still doesn't have an answer. How do we generate the first seed cases from which we build our retrieve step? Is there a better way than to randomly assemble them? Can we rely on expert insight for everything? We will answer these questions in the next chapter.
\medskip
