%---------------------------------------------------------------------
%
%                          Capï¿½tulo 2
%
%---------------------------------------------------------------------

\chapter{The program structure}

\begin{resumen}
In this chapter we provide an analysis of the program structure from an abstract point of view.
\end{resumen}

\linespread{1.6}

%-------------------------------------------------------------------
\section{The Structure}
%-------------------------------------------------------------------
\label{cap2:sec:structure}

As we have stated before, our program consists of a series of modules designed to interact with each other and provide the necessary tools to work smoothly regardless of the data being used.

Here we take a broad look at the program, trying to explain the design choices behind each aspect of it and to provide a framework of thinking for the next chapter, when we will dive deeper into the technical, low level side of things.

Our program structure needs to be flexible and adaptable, and fit the needs of both providing a basis on which to develop a CBR system and at the same time be quickly handling data, be responsive to user input, and scalable to a big data practical solution that can be used by real users for real use cases.

We will have to take into account all of this into every decision, to make sure that we're building a functional system good enough for scalability but at the same time being quick to develop for the proof of concept and the experiment to test our design choices that will allow us to try our ideas before scaling.

%-------------------------------------------------------------------
\section{Case presentation}
%-------------------------------------------------------------------
\label{cap2:sec:preparation}

The input for our program is really just an user who desires to analyze a certain dataset, so it can be conceptualized as a tuple containing a user and a dataset. This dataset will also belong to a specific domain, which will have association with the user profile aswell, so our input will be quickly transformed by the program into a domain, user, dataset concept.

From now on on this chapter, we assume we have previous information for both the domain the dataset belongs to and about the type of user that is trying to analyze it.

Our use case has the basis on the comparison of new info, represented by the dataset, to old info, represented by both the objective domain information and the subjective information associated to the profile. This flow is highly compatible with the CBR approach that we will outline in chapters 5 and 6, because we're essentially solving new problems from old problems.

Tying the new information to the old information will be done through a storage system with matching keys for the dataset and domain, being the number of columns in our proof of concept but being easily expandable into a more global system through database indexes or anything acting like a unique identifier.

The analysis of the new information will have two parts, the first one will do an isolated analysis of the new information using the techniques provided by the old, and in the second it will compare the results of the first part with the results of a similar analysis stored in the old information.

This will provide us with a new object representing the relevant information about our new problem, or dataset, and then we will filter this object using the subjective information from the profile to present the user with a final report.

The user will then have the means to modify this report, and thus modifying the subjective information about him or her.

The program will also use the new analysis to udpate the old information about the domain before proceding to store it.

We will expand on how the base cases are formed and how we adapt to new profiles and new domains on further chapters, but for now let's say that a process is in place to ensure that the default report is correct enough, the analysis performs its due processes and the result is at least acceptable and relevant to the final user.

%-------------------------------------------------------------------
\section{Handling the Information}
%-------------------------------------------------------------------
\label{cap2:sec:information}

First and foremost we need a way to store information and to retrieve it effectively. We will store two different kinds of information : objective information about the results of analysis performed on a dataset and information on what information to present and how to present it to the user.

Since the first is related to the domain and applies to all users, and the second concerns both the domain and the user, it makes sense to store them and handle them separately.

Regarding the first kind, we now provide both a way to identify which domain it belongs to and a general description of what it contains, which will be specified later during the technical implementation chapter.

It contains statistics and properties from both columns and datasets, different for different types, as well as how they were measured. Saving how they're measured is important to measure new datasets and to be able to compare metrics effectively.

Both the column specific stats and the dataset stats are subjective to change with each dataset added to the domain, so it is important that we're able to update this information readily and effectively.

It's also important to be able to distinguish between domains. The solution proposed is to use the columns of each dataset as a unique key that identifies a domain, and their objective information will be stored as part of the same object.

In the case of subjective kind, we combine this with a unique user identificator to make a unique key to identify the information.

Each of these structures has parts of the program dedicated to loading this information into the program and updating it when presented with new datasets and storing it overwriting the previous information, creating a dynamic system capable of learning from users and gathering new insights.

%-------------------------------------------------------------------
\section{Analyzing the Information}
%-------------------------------------------------------------------
\label{cap2:sec:analysis}

This analysis will concern the objective side only, so we don't need to take the user into account for now.

First a dataset is provided as input for our tool. From this dataset, we retrieve the information of the associated domain so we know how to perform the analysis on this new dataset, as it has to be comparable to the domain information.

So, using the metrics and analysis detailed in the domain information, we perform them on the dataset and compare the results with those of the domain through a series of comparison metrics which will be detailed later.

These results are then condensed into an object containing all the objective data from the comparisons.

This output will be the input for the subjective side of our program, as this information will then be filtered and transformed in a way tailored to the user.

%-------------------------------------------------------------------
\section{The Subjective Analysis}
%-------------------------------------------------------------------
\label{cap2:sec:subjective}

This analysis will concern the subjective side, and is to be performed after the previous step has been completed.

From the representation of the objective analysis, we need to perform two tasks.

One is the filtering of such information, selecting the information relevant to the user, and the other is choosing how to present this information to the user.

To perform these two tasks we first load the information we know about the user, which has been stored separately from the objective information as we have previously stated.

We then filter the information through the user provided profile, selecting which comparison is most relevant. Finally we form a report using the graphical information on how to present each bit of data to this user.

%-------------------------------------------------------------------
\section{Presentation and Feedback}
%-------------------------------------------------------------------
\label{cap2:sec:feedback}

Once the user has been presented with the report, he's able to make changes to it using a graphical interface. When the report is saved and the user has exited the program, it initializes a shutting down routine on which the two information databases are updated with the changes made by the user (if they existed) and the new information provided by the dataset.

This is essential to our CBR process as it creates a way to tie the old with the new, and greatly increases user experience as the program gets better with each iteration, as intended with the CBR methodology.

This is the main way our program has of expanding its knowledge, which will then be used to present better reports to the same user and to adapt the information it presents to new users which will be similar to this one.

So we get a double benefit, getting both better results for this user and for all users of the same domain and class each time someone uses our program.

In terms of the presentation, we have two axis on which to make decisions, visual (graph-like) content and textual content.

For the textual side, for the proof of concept we've developed a very simple template system for variables which lacks context for the specific domain and is instead tied to function results, that is, only distinguishes between categorical and numerical values for the final explanation.

On the visual side, for the proof of concept we've added pie plots, histograms and temporal graphs each with an array of different colors to choose from, because of the importance of colors in the representation of information.

It's also important to note that users are able to change the scale, size and place of the graphs in the report, which is very important for the visual impact and the user's quick and easy understanding of the information that is being presented to them.

For the user, being able to change all of these aspects represents a very important interactive side of the tool, giving power to the user as it empowers their experience with each interaction.
